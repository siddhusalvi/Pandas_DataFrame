{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataframe Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeGfaEVw/6AlJw/wMrpMET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhusalvi/Pandas_DataFrame/blob/master/Dataframe_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdknV7_2NtyR",
        "outputId": "8dda7048-e7a2-458b-d39c-cef2cc3a2e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 252 kB in 2s (127 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://04f0a93bdea4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3bb9434710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71qauY-VP0l"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQreZrNOYxrn"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.sql.functions import *"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gwWc0KY6H_"
      },
      "source": [
        "dataframe = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day1.csv\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHQM4KZY_ol",
        "outputId": "d13c9bda-fb9e-4a2c-907d-bc96b4759f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "dataframe.printSchema()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DateTime: string (nullable = true)\n",
            " |-- Cpu Count: string (nullable = true)\n",
            " |-- Cpu Working Time: string (nullable = true)\n",
            " |-- Cpu idle Time: string (nullable = true)\n",
            " |-- cpu_percent: string (nullable = true)\n",
            " |-- Usage Cpu Count : string (nullable = true)\n",
            " |-- number of software interrupts since boot: string (nullable = true)\n",
            " |-- number of system calls since boot: string (nullable = true)\n",
            " |-- number of interrupts since boot: string (nullable = true)\n",
            " |-- cpu avg load over 1 min: string (nullable = true)\n",
            " |-- cpu avg load over 5 min: string (nullable = true)\n",
            " |-- cpu avg load over 15 min: string (nullable = true)\n",
            " |-- system_total_memory: string (nullable = true)\n",
            " |-- system_used_memory: string (nullable = true)\n",
            " |-- system_free_memory: string (nullable = true)\n",
            " |-- system_active_memory: string (nullable = true)\n",
            " |-- system_inactive_memory: string (nullable = true)\n",
            " |-- system_buffers_memory: string (nullable = true)\n",
            " |-- system_cached_memory: string (nullable = true)\n",
            " |-- system_shared_memory: string (nullable = true)\n",
            " |-- system_avalible_memory: string (nullable = true)\n",
            " |-- disk_total_memory: string (nullable = true)\n",
            " |-- disk_used_memory: string (nullable = true)\n",
            " |-- disk_free_memory: string (nullable = true)\n",
            " |-- disk_read_count: string (nullable = true)\n",
            " |-- disk_write_count: string (nullable = true)\n",
            " |-- disk_read_bytes: string (nullable = true)\n",
            " |-- disk_write_bytes: string (nullable = true)\n",
            " |-- time spent reading from disk: string (nullable = true)\n",
            " |-- time spent writing to disk: string (nullable = true)\n",
            " |-- time spent doing actual I/Os: string (nullable = true)\n",
            " |-- number of bytes sent: string (nullable = true)\n",
            " |-- number of bytes received: string (nullable = true)\n",
            " |-- number of packets sent: string (nullable = true)\n",
            " |-- number of packets recived: string (nullable = true)\n",
            " |-- total number of errors while receiving: string (nullable = true)\n",
            " |-- total number of errors while sending: string (nullable = true)\n",
            " |-- total number of incoming packets which were dropped: string (nullable = true)\n",
            " |-- total number of outgoing packets which were dropped: string (nullable = true)\n",
            " |-- boot_time: string (nullable = true)\n",
            " |-- user_name: string (nullable = true)\n",
            " |-- keyboard: string (nullable = true)\n",
            " |-- mouse: string (nullable = true)\n",
            " |-- technology: string (nullable = true)\n",
            " |-- files_changed: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2JNKW7pZCC2"
      },
      "source": [
        "dataDF = dataframe.select('user_name','DateTime','keyboard','mouse')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqeSyXkoZEBw"
      },
      "source": [
        "tempDF = dataDF.withColumn(\"Date\",to_timestamp('DateTime','yyyy-MM-dd HH:mm:ss'))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REjMh4I9ZGCG"
      },
      "source": [
        "dataDF =tempDF.withColumnRenamed('user_name',\"user\")\\\n",
        ".withColumnRenamed('Date','date')\\\n",
        ".drop('DateTime')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owVDyMZ1aSTt",
        "outputId": "48ea2083-d697-4541-d577-ee6a3b1ab39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "sortedDF = dataDF.orderBy(col('user'),col('date'))\n",
        "sortedDF.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+------+-------------------+\n",
            "|                user|keyboard| mouse|               date|\n",
            "+--------------------+--------+------+-------------------+\n",
            "|antonyalexcm@gmai...|     9.0| 260.0|2019-10-13 12:10:01|\n",
            "|antonyalexcm@gmai...|     2.0|6281.0|2019-10-13 12:15:02|\n",
            "|antonyalexcm@gmai...|    61.0|5697.0|2019-10-13 12:20:01|\n",
            "|antonyalexcm@gmai...|    40.0|3940.0|2019-10-13 12:25:01|\n",
            "|antonyalexcm@gmai...|   131.0|5472.0|2019-10-13 12:30:01|\n",
            "|antonyalexcm@gmai...|   106.0|4439.0|2019-10-13 12:35:02|\n",
            "|antonyalexcm@gmai...|    86.0|3458.0|2019-10-13 12:40:01|\n",
            "|antonyalexcm@gmai...|   235.5|5364.0|2019-10-13 12:45:01|\n",
            "|antonyalexcm@gmai...|     0.0| 318.0|2019-10-13 12:50:02|\n",
            "|ashutoshrit64@gma...|     2.0| 401.0|2019-10-13 12:25:01|\n",
            "|ashutoshrit64@gma...|    64.0| 471.0|2019-10-13 12:30:02|\n",
            "|ashutoshrit64@gma...|   188.0| 349.0|2019-10-13 12:35:02|\n",
            "|ashutoshrit64@gma...|    36.0| 436.0|2019-10-13 12:40:01|\n",
            "|ashutoshrit64@gma...|    53.0| 502.0|2019-10-13 12:45:02|\n",
            "|ashutoshrit64@gma...|    17.0| 618.0|2019-10-13 12:50:01|\n",
            "|ashutoshrit64@gma...|    34.0| 611.0|2019-10-13 12:55:01|\n",
            "|ashutoshrit64@gma...|    67.0|1274.0|2019-10-13 13:00:01|\n",
            "|ashutoshrit64@gma...|   138.0| 235.0|2019-10-13 13:05:01|\n",
            "|ashutoshrit64@gma...|   125.0| 834.0|2019-10-13 13:10:01|\n",
            "|ashutoshrit64@gma...|   264.5| 899.0|2019-10-13 13:15:01|\n",
            "+--------------------+--------+------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwex3G2NcCLQ"
      },
      "source": [
        "lst1 = list(sortedDF.select('user').toPandas()['user'])\n",
        "lst2 = list(sortedDF.select('user').toPandas()['user'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWEpRERSbAL9",
        "outputId": "613f6a67-6a95-4283-c808-cc3c89c8ceaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sortedDF.drop_duplicates(['user']).count()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv6sxtlubwqa"
      },
      "source": [
        "Calculating leaves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVcaHp0Nbu1G"
      },
      "source": [
        "df1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day1.csv\")\n",
        "df2 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day2.csv\")\n",
        "df3 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day3.csv\")\n",
        "df4 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day4.csv\")\n",
        "df5 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day5.csv\")\n",
        "df6 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day6.csv\")\n",
        "df7 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day7.csv\")\n",
        "df8 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day8.csv\")\n",
        "df9 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day9.csv\")"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4xv0Yl7cmM7"
      },
      "source": [
        "day1 = df1.drop_duplicates(['user_name'])\n",
        "day2 = df2.drop_duplicates(['user_name'])\n",
        "day3 = df3.drop_duplicates(['user_name'])\n",
        "day4 = df4.drop_duplicates(['user_name'])\n",
        "day5 = df5.drop_duplicates(['user_name'])\n",
        "day6 = df6.drop_duplicates(['user_name'])\n",
        "day7 = df7.drop_duplicates(['user_name'])\n",
        "day8 = df8.drop_duplicates(['user_name'])\n",
        "day9 = df9.drop_duplicates(['user_name'])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6TvN38WiWHR"
      },
      "source": [
        "allDaysDF = day1.union(day2).union(day3).union(day4).union(day5).union(day6).union(day7).union(day8).union(day9).select('user_name')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sjlzlzEqGeQ"
      },
      "source": [
        "Total Leaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IUzXtfBkL4F",
        "outputId": "a5ba876d-4037-4e1f-a347-c615648a80f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "leavesDF = allDaysDF.groupby('user_name').count().withColumn('leaves',9 - column('count')).drop('count')\n",
        "leavesDF.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|           user_name|leaves|\n",
            "+--------------------+------+\n",
            "|ashutoshrit64@gma...|     1|\n",
            "|giridhardandikwar...|     3|\n",
            "|priyankagorte95@g...|     5|\n",
            "|       nikitapawar17|     3|\n",
            "|umangsontakke70@g...|     6|\n",
            "|salinabodale73@gm...|     8|\n",
            "|“shivnajalisangal...|     5|\n",
            "|indrajeetgajbhiye...|     3|\n",
            "|khairnarswapna99@...|     4|\n",
            "|Krushnanikam26@gm...|     5|\n",
            "|gaikwadr576@gmail...|     3|\n",
            "|adikumar2514@gmai...|     1|\n",
            "| dileep.bs@yahoo.com|     3|\n",
            "|puruissimple@gmai...|     2|\n",
            "|nehapalekar026@gm...|     7|\n",
            "|                null|     8|\n",
            "|er.mukulvij96@gma...|     2|\n",
            "|surajwarbhuvan192...|     3|\n",
            "|samruddhichitnis0...|     5|\n",
            "|yadav.ujjwal770@g...|     5|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arcRiV1oRUyH"
      },
      "source": [
        "Calculating late Commers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix1FQlgxWaP_"
      },
      "source": [
        "def getLateTiming(df):\n",
        "  from pyspark.sql.functions import lit\n",
        "  newdf = df.select('user_name','DateTime',)\\\n",
        "  .withColumn(\"Date\",to_timestamp('DateTime','yyyy-MM-dd HH:mm:ss'))\\\n",
        "  .withColumnRenamed('user_name',\"user\")\\\n",
        "  .withColumnRenamed('Date','date')\\\n",
        "  .drop('DateTime','keyboard','mouse')\\\n",
        "  .drop_duplicates(['user'])\\\n",
        "  .orderBy(col('date'))\\\n",
        "  .withColumn(\"arrivalTime\",(hour(col('date')).cast(\"Integer\") * 60 + minute(col('date')).cast(\"Integer\")))\\\n",
        "  .withColumn(\"dutyTime\",lit(510))\\\n",
        "  .withColumn(\"timeDiff\",col('dutyTime')-col('arrivalTime'))\\\n",
        "  .drop('dutyTime','arrivalTime')\n",
        "  return newdf"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_vLY1aRW266",
        "outputId": "a15581b1-99a2-48c5-bb51-d4e5b029ea86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "getLateTiming(df4).show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------------+--------+\n",
            "|                user|               date|timeDiff|\n",
            "+--------------------+-------------------+--------+\n",
            "|surajwarbhuvan192...|2019-10-16 08:45:01|     -15|\n",
            "|rahilstar11@gmail...|2019-10-16 08:50:01|     -20|\n",
            "|  shelkeva@gmail.com|2019-10-16 08:50:01|     -20|\n",
            "|prathameshsalap@g...|2019-10-16 08:55:01|     -25|\n",
            "|singladivanshu007...|2019-10-16 09:00:01|     -30|\n",
            "|khairnarswapna99@...|2019-10-16 09:00:02|     -30|\n",
            "| ingle0608@gmail.com|2019-10-16 09:05:01|     -35|\n",
            "|kalyani24deobhank...|2019-10-16 09:05:01|     -35|\n",
            "|puruissimple@gmai...|2019-10-16 09:10:01|     -40|\n",
            "|     you@example.com|2019-10-16 09:10:01|     -40|\n",
            "|sushantpatwari123...|2019-10-16 09:10:01|     -40|\n",
            "|ashutoshrit64@gma...|2019-10-16 09:15:01|     -45|\n",
            "|naineshpatil11@gm...|2019-10-16 09:15:01|     -45|\n",
            "|sharlawar77@gmail...|2019-10-16 09:15:15|     -45|\n",
            "|antonyalexcm@gmai...|2019-10-16 09:20:01|     -50|\n",
            "| grmule018@gmail.com|2019-10-16 09:20:01|     -50|\n",
            "|vaibhavkhadke@gma...|2019-10-16 09:20:02|     -50|\n",
            "|vijaykumarbhavanu...|2019-10-16 09:25:01|     -55|\n",
            "|giridhardandikwar...|2019-10-16 09:25:01|     -55|\n",
            "|indrajeetgajbhiye...|2019-10-16 09:25:01|     -55|\n",
            "+--------------------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y08FVYAhUkFT"
      },
      "source": [
        "\n",
        "from pyspark.sql.functions import to_timestamp\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SQLContext\n",
        "sqlContext = SQLContext\n",
        "sc = spark.sparkContext\n",
        "def addToRecord(record, name, time):\n",
        "    if name in record.keys():\n",
        "        time = time + record.get(name)\n",
        "        record[name] = time\n",
        "    else:\n",
        "        record[name] = time\n",
        "    return record\n",
        "\n",
        "def getIdleTime(givenDF):\n",
        "    tempDF = givenDF.select('user_name', 'DateTime', 'keyboard', 'mouse') \\\n",
        "        .withColumn(\"Date\", to_timestamp('DateTime', 'yyyy-MM-dd HH:mm:ss')) \\\n",
        "        .withColumnRenamed('user_name', \"user\") \\\n",
        "        .withColumnRenamed('Date', 'date') \\\n",
        "        .withColumn('action', col('keyboard').cast(IntegerType()) + col('mouse').cast(IntegerType())) \\\n",
        "        .drop('DateTime', 'keyboard', 'mouse') \\\n",
        "        .orderBy(col('user'), col('date'))\n",
        "    users = list(tempDF.select('user').toPandas()['user'])\n",
        "    action = list(tempDF.select('action').toPandas()['action'])\n",
        "\n",
        "    name = ''\n",
        "    counter = 0\n",
        "    output = []\n",
        "    record = {}\n",
        "\n",
        "    def addToRecord(record, name, time):\n",
        "        if name in record.keys():\n",
        "            time = time * 5 + record.get(name)\n",
        "            record[name] = time\n",
        "        else:\n",
        "            record[name] = time * 5\n",
        "        return record\n",
        "\n",
        "    for index in range(len(users)):\n",
        "        if index == 0:\n",
        "            if action[index] == 0:\n",
        "                counter = 1\n",
        "            name = users[index]\n",
        "        elif index == (len(users) - 1):\n",
        "            if ((users[index] != name) and counter > 5):\n",
        "                addToRecord(record, name, counter)\n",
        "            elif ((users[index] == name) and counter > 4 and action[index] == 0):\n",
        "                counter = counter + 1\n",
        "                addToRecord(record, name, counter)\n",
        "        else:\n",
        "            if (users[index] != name):\n",
        "                if counter < 6:\n",
        "                  counter = 0\n",
        "                record = addToRecord(record, name, counter)\n",
        "                if action[index] == 0:\n",
        "                    counter = 1\n",
        "                else:\n",
        "                    counter = 0\n",
        "                name = users[index]\n",
        "            elif action[index] == 0:\n",
        "                counter = counter + 1\n",
        "            else:\n",
        "                if counter > 5:\n",
        "                    # print(name,\" \",counter)\n",
        "                    record = addToRecord(record, name, counter)\n",
        "                counter = 0\n",
        "    lst = [(k, v) for k, v in record.items()]\n",
        "    schema = StructType([\n",
        "        StructField(\"user\", StringType(), True),\n",
        "        StructField(\"idleTime\", IntegerType(), True) ])\n",
        "\n",
        "    outputDF = spark.createDataFrame(lst, schema)\n",
        "    return outputDF"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgHqTEroVNlt"
      },
      "source": [
        "\n",
        "def getInOfficeTime(givenDF):\n",
        "  entryTimeDF =givenDF.select('user_name','DateTime')\\\n",
        "  .withColumn(\"Date\",to_timestamp('DateTime','yyyy-MM-dd HH:mm:ss'))\\\n",
        "  .withColumnRenamed('user_name',\"user\")\\\n",
        "  .withColumn('entryTime',col('Date'))\\\n",
        "  .orderBy('entryTime')\\\n",
        "  .drop_duplicates(['user'])\\\n",
        "  .drop('DateTime','Date')\\\n",
        "  .orderBy('entryTime')\n",
        "\n",
        "  exitTimeDF = givenDF.select('user_name','DateTime')\\\n",
        "  .withColumn(\"Date\",to_timestamp('DateTime','yyyy-MM-dd HH:mm:ss'))\\\n",
        "  .withColumnRenamed('user_name',\"user\")\\\n",
        "  .withColumn('exitTime',col('Date'))\\\n",
        "  .sort(col(\"exitTime\").desc())\\\n",
        "  .drop_duplicates(['user'])\\\n",
        "  .drop('DateTime','Date')\n",
        "\n",
        "  outputDF = entryTimeDF.join(exitTimeDF, on=['user'], how='inner')\n",
        "\n",
        "  return outputDF.withColumn(\"inOfficeTime\", hour(col('exitTime')).cast('Integer')*60+minute(col('exitTime')).cast('Integer') - hour(col('entryTime')).cast('Integer')*60+minute(col('entryTime')).cast('Integer') )"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQNZSJG7Ve6p"
      },
      "source": [
        "def getUserLogs(dataframe):\n",
        "  inOfficetime = getInOfficeTime(df)\n",
        "  idletime = getIdleTime(df)\n",
        "  outputDF = inOfficetime.join(idletime,on=['user'], how='outer')\\\n",
        "  .withColumn('WorkingTime',col('inOfficeTime')-col('idleTime'))\n",
        "  return outputDF"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-dYlMBjcEOU"
      },
      "source": [
        "WorkingTime of User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vbmO6gfdo7c"
      },
      "source": [
        "df9 = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"day9.csv\")"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JifzZsEMWpMA",
        "outputId": "fdf4d6f6-3ab5-4fde-af4c-d51037371077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "getUserLogs(df9).show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------------+-------------------+------------+--------+-----------+\n",
            "|                user|          entryTime|           exitTime|inOfficeTime|idleTime|WorkingTime|\n",
            "+--------------------+-------------------+-------------------+------------+--------+-----------+\n",
            "|ashutoshrit64@gma...|2019-10-13 12:25:01|2019-10-13 16:25:01|         290|      30|        260|\n",
            "| grmule018@gmail.com|2019-10-13 11:00:02|2019-10-13 17:05:02|         365|       0|        365|\n",
            "|  shelkeva@gmail.com|2019-10-13 10:25:01|2019-10-13 17:00:01|         445|      65|        380|\n",
            "|tekina.makin@gmai...|2019-10-13 12:35:01|2019-10-13 17:10:01|         345|       0|        345|\n",
            "|antonyalexcm@gmai...|2019-10-13 12:10:01|2019-10-13 12:50:02|          60|       0|         60|\n",
            "|vijaykumarbhavanu...|2019-10-13 10:55:01|2019-10-13 11:05:01|         120|       0|        120|\n",
            "|polelaxman001@gma...|2019-10-13 10:20:01|2019-10-13 14:35:11|         295|       0|        295|\n",
            "|  iamnzm@outlook.com|2019-10-13 10:20:02|2019-10-13 17:00:02|         440|      30|        410|\n",
            "|     you@example.com|2019-10-13 10:20:01|2019-10-13 17:00:02|         440|    null|       null|\n",
            "|vishnu23kumar@gma...|2019-10-13 11:20:02|2019-10-13 17:05:01|         385|       0|        385|\n",
            "|kalyani24deobhank...|2019-10-13 11:20:01|2019-10-13 16:25:01|         345|     305|         40|\n",
            "|prathameshsalap@g...|2019-10-13 10:30:02|2019-10-13 15:35:01|         365|       0|        365|\n",
            "|priyankagandhi250...|2019-10-13 12:55:01|2019-10-13 17:05:01|         360|     240|        120|\n",
            "+--------------------+-------------------+-------------------+------------+--------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}